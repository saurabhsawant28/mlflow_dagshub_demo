{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20086d7c",
   "metadata": {},
   "source": [
    "<h2 align='center'>Codebasics ML Course: ML Flow Tutorial</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2134f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a467445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([900, 100], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create an imbalanced binary classification dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=2, n_redundant=8, \n",
    "                           weights=[0.9, 0.1], flip_y=0, random_state=42)\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc473ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce174acd",
   "metadata": {},
   "source": [
    "#### Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6d768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([619, 619], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "np.unique(y_train_res, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a52b2",
   "metadata": {},
   "source": [
    "### Track Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82fdaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\n",
    "        \"Logistic Regression\", \n",
    "        {\"C\": 1, \"solver\": 'liblinear'},\n",
    "        LogisticRegression(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"Random Forest\", \n",
    "        {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "        RandomForestClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train, y_train),\n",
    "        (X_test, y_test)\n",
    "    ),\n",
    "    (\n",
    "        \"XGBClassifier With SMOTE\",\n",
    "        {\"use_label_encoder\": False, \"eval_metric\": 'logloss'},\n",
    "        XGBClassifier(), \n",
    "        (X_train_res, y_train_res),\n",
    "        (X_test, y_test)\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a992c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "\n",
    "for model_name, params, model, train_set, test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "    \n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9301bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a7ef69e-c1a9-4d2c-9691-6b7b271e9cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dagshub\n",
      "  Downloading dagshub-0.3.34-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: PyYAML>=5 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (6.0.1)\n",
      "Collecting fusepy>=3 (from dagshub)\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: appdirs>=1.4.4 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (1.4.4)\n",
      "Requirement already satisfied: click>=8.0.4 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (8.1.7)\n",
      "Collecting httpx~=0.23.0 (from dagshub)\n",
      "  Downloading httpx-0.23.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: GitPython>=3.1.29 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (3.1.37)\n",
      "Collecting rich~=13.1.0 (from dagshub)\n",
      "  Downloading rich-13.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting dacite~=1.6.0 (from dagshub)\n",
      "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: tenacity~=8.2.2 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (8.2.2)\n",
      "Collecting gql[requests] (from dagshub)\n",
      "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (0.6.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (2.1.4)\n",
      "Collecting treelib~=1.6.4 (from dagshub)\n",
      "  Downloading treelib-1.6.4-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pathvalidate~=3.0.0 (from dagshub)\n",
      "  Downloading pathvalidate-3.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dagshub) (2.8.2)\n",
      "Collecting tenacity~=8.2.2 (from dagshub)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting boto3 (from dagshub)\n",
      "  Downloading boto3-1.34.158-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\saurabh\\.conda\\lib\\site-packages (from click>=8.0.4->dagshub) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from GitPython>=3.1.29->dagshub) (4.0.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\saurabh\\.conda\\lib\\site-packages (from httpx~=0.23.0->dagshub) (2024.2.2)\n",
      "Collecting httpcore<0.17.0,>=0.15.0 (from httpx~=0.23.0->dagshub)\n",
      "  Downloading httpcore-0.16.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx~=0.23.0->dagshub)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\saurabh\\.conda\\lib\\site-packages (from httpx~=0.23.0->dagshub) (1.3.0)\n",
      "Collecting commonmark<0.10.0,>=0.9.0 (from rich~=13.1.0->dagshub)\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from rich~=13.1.0->dagshub) (2.15.1)\n",
      "Requirement already satisfied: six in c:\\users\\saurabh\\.conda\\lib\\site-packages (from treelib~=1.6.4->dagshub) (1.16.0)\n",
      "Collecting botocore<1.35.0,>=1.34.158 (from boto3->dagshub)\n",
      "  Downloading botocore-1.34.158-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from boto3->dagshub) (1.0.1)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->dagshub)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dataclasses-json->dagshub) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from dataclasses-json->dagshub) (0.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.2 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from gql[requests]->dagshub) (3.2.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.6 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from gql[requests]->dagshub) (1.9.3)\n",
      "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from gql[requests]->dagshub) (4.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.26 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from gql[requests]->dagshub) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from gql[requests]->dagshub) (1.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from pandas->dagshub) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from pandas->dagshub) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from pandas->dagshub) (2023.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from anyio<5,>=3.0->gql[requests]->dagshub) (3.4)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from botocore<1.35.0,>=1.34.158->boto3->dagshub) (2.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (4.0.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from httpcore<0.17.0,>=0.15.0->httpx~=0.23.0->dagshub) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->dagshub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from requests<3,>=2.26->gql[requests]->dagshub) (2.0.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (4.9.0)\n",
      "Requirement already satisfied: multidict>=4.0 in c:\\users\\saurabh\\.conda\\lib\\site-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.0.4)\n",
      "Downloading dagshub-0.3.34-py3-none-any.whl (236 kB)\n",
      "   ---------------------------------------- 0.0/236.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 236.6/236.6 kB 7.1 MB/s eta 0:00:00\n",
      "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading httpx-0.23.3-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.5/71.5 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading pathvalidate-3.0.0-py3-none-any.whl (21 kB)\n",
      "Downloading rich-13.1.0-py3-none-any.whl (238 kB)\n",
      "   ---------------------------------------- 0.0/238.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  235.5/238.4 kB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 238.4/238.4 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading treelib-1.6.4-py3-none-any.whl (18 kB)\n",
      "Downloading boto3-1.34.158-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading botocore-1.34.158-py3-none-any.whl (12.5 MB)\n",
      "   ---------------------------------------- 0.0/12.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.6/12.5 MB 17.8 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.0/12.5 MB 11.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.5/12.5 MB 10.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.1/12.5 MB 10.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/12.5 MB 10.0 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.7/12.5 MB 9.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 3.0/12.5 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 3.4/12.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.8/12.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 4.2/12.5 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.5 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.0/12.5 MB 8.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.3/12.5 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 6.2/12.5 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.6/12.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.0/12.5 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.0/12.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 7.0/12.5 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.9/12.5 MB 8.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.9/12.5 MB 8.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.2/12.5 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.6/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.1/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 11.1/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.4/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.0/12.5 MB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.5/12.5 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.5/12.5 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.1/51.1 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
      "   ---------------------------------------- 0.0/69.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 69.6/69.6 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.7/82.7 kB 4.5 MB/s eta 0:00:00\n",
      "Downloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/74.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 74.0/74.0 kB 2.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: fusepy\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10501 sha256=520288f6563a96a1f35c02c039a90d02e96b3b7e3f3ae54e36f04fb929533b65\n",
      "  Stored in directory: c:\\users\\saurabh\\appdata\\local\\pip\\cache\\wheels\\db\\4a\\86\\fdda91f8b8ebb0a70e4181dc2423b1f70c3c2d3bd1158685b5\n",
      "Successfully built fusepy\n",
      "Installing collected packages: rfc3986, fusepy, commonmark, treelib, tenacity, rich, pathvalidate, dacite, backoff, httpcore, gql, botocore, s3transfer, httpx, boto3, dagshub\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.3.5\n",
      "    Uninstalling rich-13.3.5:\n",
      "      Successfully uninstalled rich-13.3.5\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.5\n",
      "    Uninstalling httpcore-1.0.5:\n",
      "      Successfully uninstalled httpcore-1.0.5\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.64\n",
      "    Uninstalling botocore-1.31.64:\n",
      "      Successfully uninstalled botocore-1.31.64\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "Successfully installed backoff-2.2.1 boto3-1.34.158 botocore-1.34.158 commonmark-0.9.1 dacite-1.6.0 dagshub-0.3.34 fusepy-3.0.1 gql-3.5.0 httpcore-0.16.3 httpx-0.23.3 pathvalidate-3.0.0 rfc3986-1.5.0 rich-13.1.0 s3transfer-0.10.2 tenacity-8.2.3 treelib-1.6.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.158 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ea79ef-9ae7-42a1-8e3e-a0522bd3bff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=b9695da6-c0b6-4119-8bbb-5b6f1e923c05&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=1617f8e7413c1707bf33d03e54237c08daf0d0c15f7b0c1656e99da16602214d\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as saurabhsawant28\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as saurabhsawant28\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"saurabhsawant28/mlflow_dagshub_demo\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"saurabhsawant28/mlflow_dagshub_demo\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository saurabhsawant28/mlflow_dagshub_demo initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository saurabhsawant28/mlflow_dagshub_demo initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dagshub setup\n",
    "import dagshub\n",
    "dagshub.init(repo_owner='saurabhsawant28', repo_name='mlflow_dagshub_demo', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad9cf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/12 14:34:54 INFO mlflow.tracking.fluent: Experiment with name 'Anomaly Detection' does not exist. Creating a new experiment.\n",
      "2024/08/12 14:35:21 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/12 14:35:21 INFO mlflow.tracking._tracking_service.client: üèÉ View run Logistic Regression at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0/runs/f6810279c2fe4595b9f354fd9a622976.\n",
      "2024/08/12 14:35:21 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0.\n",
      "2024/08/12 14:35:39 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/12 14:35:39 INFO mlflow.tracking._tracking_service.client: üèÉ View run Random Forest at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0/runs/32c51deb80be49199f507571f6c84a4b.\n",
      "2024/08/12 14:35:39 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0.\n",
      "2024/08/12 14:35:54 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/12 14:35:54 INFO mlflow.tracking._tracking_service.client: üèÉ View run XGBClassifier at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0/runs/e95bf49dec044656aa510a104ab97bf3.\n",
      "2024/08/12 14:35:54 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0.\n",
      "2024/08/12 14:36:08 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/12 14:36:08 INFO mlflow.tracking._tracking_service.client: üèÉ View run XGBClassifier With SMOTE at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0/runs/541b6bc21a3c4b1690b549f33db3fc00.\n",
      "2024/08/12 14:36:08 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLflow\n",
    "mlflow.set_experiment(\"Anomaly Detection\")\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/saurabhsawant28/mlflow_dagshub_demo.mlflow\")\n",
    "\n",
    "for i, element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    params = element[1]\n",
    "    model = element[2]\n",
    "    report = reports[i]\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):        \n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            'accuracy': report['accuracy'],\n",
    "            'recall_class_1': report['1']['recall'],\n",
    "            'recall_class_0': report['0']['recall'],\n",
    "            'f1_score_macro': report['macro avg']['f1-score']\n",
    "        })  \n",
    "        \n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, \"model\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, \"model\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446ae8a",
   "metadata": {},
   "source": [
    "### Register the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'XGB-Smote'\n",
    "run_id=input('Please type RunID')\n",
    "model_uri = f'runs:/{run_id}/model_name'\n",
    "\n",
    "with mlflow.start_run(run_id=run_id):\n",
    "    mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b074a08",
   "metadata": {},
   "source": [
    "### Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a40fef12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d2893",
   "metadata": {},
   "source": [
    "### Transition the Model to Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c8ac1e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1722288798033, current_stage='None', description='', last_updated_timestamp=1722288798033, name='anomaly-detection-prod', run_id='3e6b0bdb88ac4df9add7a826594d8d33', run_link='', source='models:/XGB-Smote/1', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model_uri = f\"models:/{model_name}@challenger\"\n",
    "production_model_name = \"anomaly-detection-prod\"\n",
    "\n",
    "client = mlflow.MlflowClient()\n",
    "client.copy_model_version(src_model_uri=current_model_uri, dst_name=production_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4297a2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 1\n",
    "prod_model_uri = f\"models:/{production_model_name}@champion\"\n",
    "\n",
    "loaded_model = mlflow.xgboost.load_model(prod_model_uri)\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca565a87",
   "metadata": {},
   "source": [
    "Please refer to following to learn more about model registry\n",
    "\n",
    "https://mlflow.org/docs/latest/model-registry.html#model-registry-workflows to learn "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
